<!-- Powered by BMAD™ Core -->

# Story 1.03: Background Job Queue (Celery + Redis)

**Status:** Done  
**Epic:** 1 – Core Backend Service  
**Created:** 2025-10-16  
**Author:** PO Agent

---

## Story
**As a** frequent user downloading large playlists,  
**I want** the backend to process downloads in a background queue,  
**so that** the service remains responsive and can handle multiple concurrent requests without timing out.

---

## Acceptance Criteria
1. Celery integrated into backend with Redis (free hosted tier) as broker.
2. `POST /download` now enqueues Celery task and returns downloadId immediately.
3. Celery worker executes yt-dlp job, updates progress in Redis (or backend DB) accessible via status endpoint.
4. `GET /download/status/{id}` retrieves real-time progress from task meta; includes percentage & speed.
5. Worker concurrency set via env `CELERY_CONCURRENCY` (default 2) to respect free-tier limits.
6. Docker Compose file added for local dev with `backend`, `worker`, and `redis` services.
7. Health check `/healthz` extended to show OK only if Redis reachable.
8. README updated with instructions to run compose and deploy worker on Render/Railway.
9. Automated tests cover enqueue, status polling, and success/error paths (mocked Redis in unit tests).
10. Existing UI flow continues to work unchanged (Story 1.02 acceptance tests still pass).

---

## Tasks / Subtasks
- [x] Install dependencies: `celery[redis]`, `aioredis`, `python-dotenv` update requirements.
- [x] Create `app/celery_worker.py` with Celery app and discovery.
- [x] Refactor `downloader.py` functions into Celery tasks with `bind=True`, report progress via `update_state`.
- [x] Update `download.py` router to call `celery_app.send_task()` instead of in-process async task.
- [x] Implement `status` endpoint reading task result/progress via `AsyncResult`.
- [ ] Add `docker-compose.yml` with backend, worker, redis services. (User opted not to use Docker, may be skipped)
- [x] Add `scripts/run_worker.sh` for Render deploy.
- [x] Update `.env.example` with Redis URL and concurrency settings.
- [ ] Write unit tests with `celery.app.control.inspect` mocked.
- [ ] Update GitHub Actions workflow to spin up Redis service for backend tests.

---

## Dev Notes
- Use `redis://localhost:6379/0` for local; `REDIS_URL` env overrides.
- For free hosted Redis (e.g., Upstash) ensure TLS connection; Celery supports rediss protocol.
- Set task hard-time-limit 10 min via Celery config to avoid runaway jobs.
- Progress granularity: parse yt-dlp JSON lines, push percentage in `.update_state(meta={})`.
- Consider fallback to in-process mode if `REDIS_URL` missing (MVP compatibility).

---

## Testing Standards
- Unit tests in `tests/celery/` mocking Redis.
- Integration test spins up ephemeral Redis container via `pytest-docker` and asserts task flow.
- Maintain ≥ 80 % coverage across new modules.

---

## Change Log
| Date       | Version | Description                        | Author     |
|------------|---------|------------------------------------|------------|
| 2025-10-16 | 1.0     | Initial story created              | PO Agent   |

---

## Dev Agent Record
*Populated by dev agent during implementation.*

### Agent Model Used
*

### Debug Log References
*

### Completion Notes
*

### File List
*